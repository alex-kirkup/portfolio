{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dca8247",
   "metadata": {},
   "source": [
    "# Predicting GCSE grades from prior assessments\n",
    "\n",
    "The aim of this project is to determine if machine learning models can outperform classroom teachers in predicting pupils' final examination grades.\n",
    "\n",
    "The setting is a UK secondary school where pupils have attended for 5 years before sitting their final GCSE exams at age 16.\n",
    "\n",
    "Our data will be the results of pupils' in-class assessments and their final GCSE results.\n",
    "\n",
    "To select the most appropriate model to make predictions we will spot-check a range of classification models and some common hyperparameters and rank them according by the proportion of accurate predictions made. \n",
    "\n",
    "If we find a model that could predict with greater accuracy than a classroom teacher then we will dive a little deeper and try to maximise the model's predictive accuracy and consider deploying the model for future use.\n",
    "\n",
    "*Spoiler alert: the model created in this project offers about the same predictive accuracy as a classroom teacher. There still may be benefits of continuing to use the model, however. You can jump to the [conclusion](#conclusion) to explore my findings and evaluation further.*\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Define the problem](#define_problem)\n",
    "2. [Success criteria](#success_criteria)\n",
    "3. [Data collection](#data_collection)\n",
    "4. [Data preparation, EDA, feature engineering](#EDA)\n",
    "5. [Modelling](#modelling)\n",
    "6. [Experimentation](#experiment)\n",
    "\n",
    "\n",
    "## Define the problem\n",
    "<a name=\"define_problem\"></a>\n",
    "\n",
    "In the school where I work mathematics teachers usually predict GCSE grades with between 50% and 60% accuracy each year. As a maths teacher myself I know how tricky the process is on so many levels. For example:\n",
    "1. when it is too hard to call between one grade and another\n",
    "2. some pupils can unexpectedly underperform or overperform in their exams\n",
    "3. having taught pupils for sometimes 2 or 3 years it is impossible to be objective in my own judgement of their capabilities when I have been working so hard to make sure they do well\n",
    "\n",
    "\n",
    "## Define success criteria\n",
    "<a name=\"success_criteria\"></a>\n",
    "\n",
    "In light of this, a machine learning model with over 60% accuracy in predictions will be worth exploring further.\n",
    "\n",
    "\n",
    "## Data collection\n",
    "<a name=\"data_collection\"></a>\n",
    "\n",
    "The pupil data we have collected constsists of test scores in mathematics collected during each pupil's five years of secondary school. \n",
    "\n",
    "The data is collected by question, and is grouped by either by total score (e.g. TEST 5: 61/80) or by skill (FRACTIONS: 72%).\n",
    "Have a look at my Medium post __[How to make the most of pupil data](https://medium.com/@alex.kirkup/making-the-most-of-pupil-data-7aca41e53d97)__ which explains our processes and how skills feedback has significantly improved pupils' learning.\n",
    "\n",
    "Our new scheme of assessment has six tests in years 7, 8 and 9; four tests in year 10; an end of year mock exam at the end of year 10; and two mock exams during year 11. \n",
    "\n",
    "However you will notice that some of the data is from the old scheme of assessment and has different titles.\n",
    "\n",
    "Furthermore there are some missing test results which are due to interruptions to schooling during the pandemic.\n",
    "\n",
    "Importantly, there are not many records - 226 in all.\n",
    "\n",
    "\n",
    "### Dealing with two different ways to look at the data.\n",
    "\n",
    "Having data which can be grouped in two different ways gives me two different avenues to explore.\n",
    "\n",
    "Initially I will use the data for total scores and see whether this can produce accurate predictions, and then try by skill. As a by-product, it would be of great value for example if a particular skill such as algebra was correlated strongly with final grades.\n",
    "\n",
    "## Data preparation, EDA, feature engineering\n",
    "<a name=\"EDA\"></a>\n",
    "\n",
    "First, to take into account the different tests, I will average the score for each year as a proportion of the total (0 to 1).\n",
    "\n",
    "Second, there are various possible ways to deal with missing values (in this case missing test results), and I am not certain which is best. I will create two dataframes, one with missing scores omitted (df1), another with missing scores being given the median value for that test (df2). \n",
    "\n",
    "With such a small dataset I feel that omitting rows might be model-breaking, however using the median might skew results away from the pupil's actual potential.\n",
    "\n",
    "In light of this I will run each model I test with both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fbaf81",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866dda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# disable warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae60635",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a50200b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 226 entries, 0 to 225\n",
      "Data columns (total 51 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   id                             226 non-null    int64  \n",
      " 1   Y7 EOY Delta 1                 85 non-null     float64\n",
      " 2   Unnamed: 2                     85 non-null     float64\n",
      " 3   Y7 EOY Delta 2                 85 non-null     float64\n",
      " 4   Unnamed: 4                     85 non-null     float64\n",
      " 5   Y7 EOY Higher Tier Test        71 non-null     float64\n",
      " 6   Unnamed: 6                     0 non-null      float64\n",
      " 7   Y7 AVG                         156 non-null    float64\n",
      " 8   Unnamed: 8                     89 non-null     float64\n",
      " 9   Unnamed: 9                     89 non-null     float64\n",
      " 10  Unnamed: 10                    48 non-null     float64\n",
      " 11  Unnamed: 11                    48 non-null     float64\n",
      " 12  Unnamed: 12                    86 non-null     float64\n",
      " 13  Unnamed: 13                    86 non-null     float64\n",
      " 14  Unnamed: 14                    91 non-null     float64\n",
      " 15  Unnamed: 15                    91 non-null     float64\n",
      " 16  Y8 Term 1 Test HA              101 non-null    float64\n",
      " 17  Unnamed: 17                    101 non-null    float64\n",
      " 18  Y8 Term 2 Test HA              101 non-null    float64\n",
      " 19  Unnamed: 19                    101 non-null    float64\n",
      " 20  Y8 Term 3 Test HA              101 non-null    float64\n",
      " 21  Unnamed: 21                    101 non-null    float64\n",
      " 22  Y8 AVG                         197 non-null    float64\n",
      " 23  Y9 Term 1 Test HA              96 non-null     float64\n",
      " 24  Unnamed: 24                    190 non-null    float64\n",
      " 25  Y9 Term 2 Test HA              77 non-null     float64\n",
      " 26  Unnamed: 26                    170 non-null    float64\n",
      " 27  Y9 Term 5 Test HA              96 non-null     float64\n",
      " 28  Unnamed: 28                    170 non-null    float64\n",
      " 29  Y9 Term 6 Test HA              94 non-null     float64\n",
      " 30  Unnamed: 30                    94 non-null     float64\n",
      " 31  Y9 AVG                         195 non-null    float64\n",
      " 32  Y10 Term 1 Test H              103 non-null    float64\n",
      " 33  Unnamed: 33                    103 non-null    float64\n",
      " 34  Y10 Term 2 Test H              103 non-null    float64\n",
      " 35  Unnamed: 35                    103 non-null    float64\n",
      " 36  Y10 Term 3 Test H              99 non-null     float64\n",
      " 37  Unnamed: 37                    99 non-null     float64\n",
      " 38  Y10 Term 4 Test H              104 non-null    float64\n",
      " 39  Unnamed: 39                    104 non-null    float64\n",
      " 40  Y10 AVG                        205 non-null    float64\n",
      " 41  Y10 EOY Mock Higher Paper 1    104 non-null    float64\n",
      " 42  Y10 EOY Mock Higher Paper 2    104 non-null    float64\n",
      " 43  Y10 MOCK AVG                   205 non-null    float64\n",
      " 44  Y11 Nov Mock Higher Paper 1    102 non-null    float64\n",
      " 45  Y11 Nov Mock Higher Paper 2    102 non-null    float64\n",
      " 46  Y11 NOV MOCK AVG               207 non-null    float64\n",
      " 47  Y11 March Mock Higher Paper 1  104 non-null    float64\n",
      " 48  Y11 March Mock Higher Paper 2  104 non-null    float64\n",
      " 49  Y11 MAR MOCK AVG               225 non-null    float64\n",
      " 50  Final grade                    226 non-null    int64  \n",
      "dtypes: float64(49), int64(2)\n",
      "memory usage: 90.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/gcse-higher-avg.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d074a61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 51)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb757e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Y7 EOY Delta 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Y7 EOY Delta 2</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Y7 EOY Higher Tier Test</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Y7 AVG</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Y10 EOY Mock Higher Paper 1</th>\n",
       "      <th>Y10 EOY Mock Higher Paper 2</th>\n",
       "      <th>Y10 MOCK AVG</th>\n",
       "      <th>Y11 Nov Mock Higher Paper 1</th>\n",
       "      <th>Y11 Nov Mock Higher Paper 2</th>\n",
       "      <th>Y11 NOV MOCK AVG</th>\n",
       "      <th>Y11 March Mock Higher Paper 1</th>\n",
       "      <th>Y11 March Mock Higher Paper 2</th>\n",
       "      <th>Y11 MAR MOCK AVG</th>\n",
       "      <th>Final grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.48125</td>\n",
       "      <td>52.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.57500</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.55625</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.58750</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.54375</td>\n",
       "      <td>49.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.51250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.64375</td>\n",
       "      <td>60.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.66875</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>78.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Y7 EOY Delta 1  Unnamed: 2  Y7 EOY Delta 2  Unnamed: 4  \\\n",
       "0  1273             NaN         NaN             NaN         NaN   \n",
       "1  1274             NaN         NaN             NaN         NaN   \n",
       "2  1275             NaN         NaN             NaN         NaN   \n",
       "3  1276             NaN         NaN             NaN         NaN   \n",
       "4  1277             NaN         NaN             NaN         NaN   \n",
       "\n",
       "   Y7 EOY Higher Tier Test  Unnamed: 6  Y7 AVG  Unnamed: 8  Unnamed: 9  ...  \\\n",
       "0                     51.0         NaN    0.51         NaN         NaN  ...   \n",
       "1                     62.0         NaN    0.62         NaN         NaN  ...   \n",
       "2                     49.0         NaN    0.49         NaN         NaN  ...   \n",
       "3                     78.0         NaN    0.78         NaN         NaN  ...   \n",
       "4                     91.0         NaN    0.91         NaN         NaN  ...   \n",
       "\n",
       "   Y10 EOY Mock Higher Paper 1  Y10 EOY Mock Higher Paper 2  Y10 MOCK AVG  \\\n",
       "0                         29.0                         48.0       0.48125   \n",
       "1                         41.0                         53.0       0.58750   \n",
       "2                         40.0                         47.0       0.54375   \n",
       "3                         42.0                         61.0       0.64375   \n",
       "4                         57.0                         70.0       0.79375   \n",
       "\n",
       "   Y11 Nov Mock Higher Paper 1  Y11 Nov Mock Higher Paper 2  Y11 NOV MOCK AVG  \\\n",
       "0                         52.0                         40.0           0.57500   \n",
       "1                         60.0                         50.0           0.68750   \n",
       "2                         49.0                         56.0           0.65625   \n",
       "3                         60.0                         47.0           0.66875   \n",
       "4                         75.0                         70.0           0.90625   \n",
       "\n",
       "   Y11 March Mock Higher Paper 1  Y11 March Mock Higher Paper 2  \\\n",
       "0                           52.0                           37.0   \n",
       "1                           53.0                           52.0   \n",
       "2                           39.0                           43.0   \n",
       "3                           52.0                           52.0   \n",
       "4                           78.0                           74.0   \n",
       "\n",
       "   Y11 MAR MOCK AVG  Final grade  \n",
       "0           0.55625            6  \n",
       "1           0.65625            8  \n",
       "2           0.51250            6  \n",
       "3           0.65000            7  \n",
       "4           0.95000            9  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a744c7",
   "metadata": {},
   "source": [
    "Keep only the averages for each year and each mock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86d38d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y7 AVG</th>\n",
       "      <th>Y8 AVG</th>\n",
       "      <th>Y9 AVG</th>\n",
       "      <th>Y10 AVG</th>\n",
       "      <th>Y10 MOCK AVG</th>\n",
       "      <th>Y11 NOV MOCK AVG</th>\n",
       "      <th>Y11 MAR MOCK AVG</th>\n",
       "      <th>Final grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.48125</td>\n",
       "      <td>0.57500</td>\n",
       "      <td>0.55625</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.647917</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.58750</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.539583</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.54375</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>0.51250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>0.668750</td>\n",
       "      <td>0.64375</td>\n",
       "      <td>0.66875</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y7 AVG    Y8 AVG    Y9 AVG   Y10 AVG  Y10 MOCK AVG  Y11 NOV MOCK AVG  \\\n",
       "0    0.51  0.544444  0.488889  0.510417       0.48125           0.57500   \n",
       "1    0.62  0.727778  0.647917  0.775000       0.58750           0.68750   \n",
       "2    0.49  0.761111  0.539583  0.666667       0.54375           0.65625   \n",
       "3    0.78  0.877778  0.631250  0.668750       0.64375           0.66875   \n",
       "4    0.91  0.972222  0.816667  0.979167       0.79375           0.90625   \n",
       "\n",
       "   Y11 MAR MOCK AVG  Final grade  \n",
       "0           0.55625            6  \n",
       "1           0.65625            8  \n",
       "2           0.51250            6  \n",
       "3           0.65000            7  \n",
       "4           0.95000            9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Y7 AVG','Y8 AVG','Y9 AVG','Y10 AVG','Y10 MOCK AVG','Y11 NOV MOCK AVG','Y11 MAR MOCK AVG','Final grade']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef38d058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65a11f",
   "metadata": {},
   "source": [
    "### Replace missing values\n",
    "\n",
    "Pupils may have missed tests for various reasons. We will try 1) replacing these with the median, and 2) removing these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1151e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y7 AVG</th>\n",
       "      <th>Y8 AVG</th>\n",
       "      <th>Y9 AVG</th>\n",
       "      <th>Y10 AVG</th>\n",
       "      <th>Y10 MOCK AVG</th>\n",
       "      <th>Y11 NOV MOCK AVG</th>\n",
       "      <th>Y11 MAR MOCK AVG</th>\n",
       "      <th>Final grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.48125</td>\n",
       "      <td>0.57500</td>\n",
       "      <td>0.55625</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.647917</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.58750</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.539583</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.54375</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>0.51250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>0.668750</td>\n",
       "      <td>0.64375</td>\n",
       "      <td>0.66875</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y7 AVG    Y8 AVG    Y9 AVG   Y10 AVG  Y10 MOCK AVG  Y11 NOV MOCK AVG  \\\n",
       "0    0.51  0.544444  0.488889  0.510417       0.48125           0.57500   \n",
       "1    0.62  0.727778  0.647917  0.775000       0.58750           0.68750   \n",
       "2    0.49  0.761111  0.539583  0.666667       0.54375           0.65625   \n",
       "3    0.78  0.877778  0.631250  0.668750       0.64375           0.66875   \n",
       "4    0.91  0.972222  0.816667  0.979167       0.79375           0.90625   \n",
       "\n",
       "   Y11 MAR MOCK AVG  Final grade  \n",
       "0           0.55625            6  \n",
       "1           0.65625            8  \n",
       "2           0.51250            6  \n",
       "3           0.65000            7  \n",
       "4           0.95000            9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.fillna(df.median())\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b4bb1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ab455d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y7 AVG</th>\n",
       "      <th>Y8 AVG</th>\n",
       "      <th>Y9 AVG</th>\n",
       "      <th>Y10 AVG</th>\n",
       "      <th>Y10 MOCK AVG</th>\n",
       "      <th>Y11 NOV MOCK AVG</th>\n",
       "      <th>Y11 MAR MOCK AVG</th>\n",
       "      <th>Final grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.48125</td>\n",
       "      <td>0.57500</td>\n",
       "      <td>0.55625</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.647917</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.58750</td>\n",
       "      <td>0.68750</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.539583</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.54375</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>0.51250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>0.668750</td>\n",
       "      <td>0.64375</td>\n",
       "      <td>0.66875</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y7 AVG    Y8 AVG    Y9 AVG   Y10 AVG  Y10 MOCK AVG  Y11 NOV MOCK AVG  \\\n",
       "0    0.51  0.544444  0.488889  0.510417       0.48125           0.57500   \n",
       "1    0.62  0.727778  0.647917  0.775000       0.58750           0.68750   \n",
       "2    0.49  0.761111  0.539583  0.666667       0.54375           0.65625   \n",
       "3    0.78  0.877778  0.631250  0.668750       0.64375           0.66875   \n",
       "4    0.91  0.972222  0.816667  0.979167       0.79375           0.90625   \n",
       "\n",
       "   Y11 MAR MOCK AVG  Final grade  \n",
       "0           0.55625            6  \n",
       "1           0.65625            8  \n",
       "2           0.51250            6  \n",
       "3           0.65000            7  \n",
       "4           0.95000            9  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.dropna()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3eefacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d51edd",
   "metadata": {},
   "source": [
    "Neither method is perfect, however a reduction of nearly 100 rows because of missing values for df2 is highly significant. We will have to see how this impacts the accuracy of the model's predictions.\n",
    "\n",
    "Finally, let's create a list of df1 and df2 ready to try both with each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e0de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1,df2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0767f3",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "<a name=\"modelling\"></a>\n",
    "\n",
    "We will select the three best models by spot checking. My inspiration for this was from __[this](https://machinelearningmastery.com/spot-check-machine-learning-algorithms-in-python/)__ template from Jason Brownlee at Machine Learning Mastery.\n",
    "\n",
    "First, how will we judge if a model is successful or not?\n",
    "\n",
    "### How to measure predictive accuracy\n",
    "\n",
    "Bex T's Medium article __[here](https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd)__ gives a fantastic overview of the metrics that can be applied to this sort of multiclass-classification problem.\n",
    "\n",
    "**Accuracy** is the appropriate measurement we will need, as the score it returns will be the proportion of correct predictions - all other results are incorrect irrespective of how wide of the mark they are.\n",
    "\n",
    "**Cross validation** will be essential here because of the small sample size. With 226 records, an 80-20 train-test split will provide only 45 results for the test. This is potentially so small that there will be a high variability due to chance from our machine learning model. Dima Shulga gives a great explanation of this __[here](https://towardsdatascience.com/5-reasons-why-you-should-use-cross-validation-in-your-data-science-project-8163311a1e79)__. Cross validation allows us to get more metrics and draw better conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadec20a",
   "metadata": {},
   "source": [
    "### Create a dict of classification models with common hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1d0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# function which can take a dict of already-existing models as an argument\n",
    "def define_models(models=dict()):\n",
    "    \n",
    "    # linear models\n",
    "    models['logistic'] = LogisticRegression(random_state = 42)\n",
    "    for a in [0.3, 0.7, 1.0]:\n",
    "        models['ridge-'+str(a)] = RidgeClassifier(alpha=a, random_state = 42)\n",
    "    models['sgd'] = SGDClassifier(max_iter=1000, tol=1e-3, random_state = 42)\n",
    "    models['pa'] = PassiveAggressiveClassifier(max_iter=1000, tol=1e-3, random_state = 42)\n",
    "    \n",
    "    # non-linear models\n",
    "    n_neighbors = [3,7,15]\n",
    "    for k in n_neighbors:\n",
    "        models['knn-'+str(k)] = KNeighborsClassifier(n_neighbors=k)\n",
    "    models['cart'] = DecisionTreeClassifier(random_state = 42)\n",
    "    models['extra'] = ExtraTreeClassifier(random_state = 42)\n",
    "    models['svml'] = SVC(kernel='linear', random_state = 42)\n",
    "    models['svmp'] = SVC(kernel='poly', random_state = 42)\n",
    "    for c in [0.3, 0.7, 1.0]:\n",
    "        models['svmr'+str(c)] = SVC(C=c, random_state = 42)\n",
    "    models['bayes'] = GaussianNB()\n",
    " \n",
    "    # ensemble models\n",
    "    n_trees = 100\n",
    "    models['ada'] = AdaBoostClassifier(n_estimators=n_trees, random_state = 42)\n",
    "    models['bag'] = BaggingClassifier(n_estimators=n_trees, random_state = 42)\n",
    "    models['rf'] = RandomForestClassifier(n_estimators=n_trees, random_state = 42)\n",
    "    models['et'] = ExtraTreesClassifier(n_estimators=n_trees, random_state = 42)\n",
    "    models['gbm'] = GradientBoostingClassifier(n_estimators=n_trees, random_state = 42)\n",
    "    \n",
    "    print(f'Defined {len(models)} models')\n",
    "    print()\n",
    " \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8cfa13",
   "metadata": {},
   "source": [
    "### Create a function to generalise the process of predicting and calculating accuracy for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70543795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "def predict_and_calc_accuracy(model, X, y):\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    \n",
    "    # Fit\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Cross-validation\n",
    "    accuracy = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring='accuracy',\n",
    "        cv=5,\n",
    "    )\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8378281",
   "metadata": {},
   "source": [
    "### Spot check the classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36cd0793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 22 models\n",
      "\n",
      "logistic, df1 = 0.4667\n",
      "logistic, df2 = 0.5565\n",
      "ridge-0.3, df1 = 0.4333\n",
      "ridge-0.3, df2 = 0.487\n",
      "ridge-0.7, df1 = 0.4389\n",
      "ridge-0.7, df2 = 0.487\n",
      "ridge-1.0, df1 = 0.4222\n",
      "ridge-1.0, df2 = 0.4783\n",
      "sgd, df1 = 0.3167\n",
      "sgd, df2 = 0.3739\n",
      "pa, df1 = 0.4\n",
      "pa, df2 = 0.3478\n",
      "knn-3, df1 = 0.4667\n",
      "knn-3, df2 = 0.513\n",
      "knn-7, df1 = 0.4833\n",
      "knn-7, df2 = 0.5217\n",
      "knn-15, df1 = 0.5611\n",
      "knn-15, df2 = 0.5739\n",
      "cart, df1 = 0.5333\n",
      "cart, df2 = 0.5826\n",
      "extra, df1 = 0.5111\n",
      "extra, df2 = 0.5565\n",
      "svml, df1 = 0.5\n",
      "svml, df2 = 0.6348\n",
      "svmp, df1 = 0.6167\n",
      "svmp, df2 = 0.6\n",
      "svmr0.3, df1 = 0.4889\n",
      "svmr0.3, df2 = 0.6174\n",
      "svmr0.7, df1 = 0.5556\n",
      "svmr0.7, df2 = 0.5739\n",
      "svmr1.0, df1 = 0.5667\n",
      "svmr1.0, df2 = 0.5043\n",
      "bayes, df1 = 0.5833\n",
      "bayes, df2 = 0.6\n",
      "ada, df1 = 0.4167\n",
      "ada, df2 = 0.4522\n",
      "bag, df1 = 0.65\n",
      "bag, df2 = 0.6348\n",
      "rf, df1 = 0.5556\n",
      "rf, df2 = 0.6\n",
      "et, df1 = 0.6222\n",
      "et, df2 = 0.5826\n",
      "gbm, df1 = 0.65\n",
      "gbm, df2 = 0.6261\n",
      "\n",
      "Best 10\n",
      "=======\n",
      "[('bag, df1', 0.65),\n",
      " ('gbm, df1', 0.65),\n",
      " ('svml, df2', 0.6348),\n",
      " ('bag, df2', 0.6348),\n",
      " ('gbm, df2', 0.6261),\n",
      " ('et, df1', 0.6222),\n",
      " ('svmr0.3, df2', 0.6174),\n",
      " ('svmp, df1', 0.6167),\n",
      " ('svmp, df2', 0.6),\n",
      " ('bayes, df2', 0.6)]\n"
     ]
    }
   ],
   "source": [
    "models = define_models()\n",
    "\n",
    "results = {}\n",
    "        \n",
    "for key,model in models.items(): \n",
    "\n",
    "    # Go\n",
    "    counter = 0\n",
    "    for df in df_list:\n",
    "        \n",
    "        counter += 1\n",
    "\n",
    "        # Create X (all the feature columns)\n",
    "        X = df_list[counter-1].drop([\"Final grade\"], axis=1)\n",
    "\n",
    "        # Create y (the target column)\n",
    "        y = df_list[counter-1][\"Final grade\"]\n",
    "\n",
    "        # Get results\n",
    "        model_result = np.mean(predict_and_calc_accuracy(model, X, y))\n",
    "        model_result = round(model_result, 4)\n",
    "        results[f'{key}, df{counter}'] = model_result\n",
    "        print(f'{key}, df{counter} = {model_result}')\n",
    "        \n",
    "results = sorted(results.items(),reverse=True,key=lambda item: item[1])[:10]\n",
    "\n",
    "print()\n",
    "print(\"Best 10\")\n",
    "print(\"=======\")\n",
    "pp.pprint(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4bc51",
   "metadata": {},
   "source": [
    "There are a small number of models scoring above 60% accuracy which is promising.\n",
    "\n",
    "Let's next look at our second way of looking at the data - i.e. by skill - to see if it offers any improvement in making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1872735",
   "metadata": {},
   "source": [
    "### Round 2 - try the same steps again with data by skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed383aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215 entries, 0 to 214\n",
      "Data columns (total 20 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Name                       215 non-null    object \n",
      " 1   Final year                 215 non-null    int64  \n",
      " 2   Class                      215 non-null    object \n",
      " 3   TOPIC: NUMBER SKILLS       215 non-null    object \n",
      " 4   TOPIC: FRACTIONS           215 non-null    object \n",
      " 5   TOPIC: PERCENTAGES         215 non-null    object \n",
      " 6   TOPIC: RATIO & PROPORTION  215 non-null    object \n",
      " 7   TOPIC: ALGEBRA SKILLS      215 non-null    object \n",
      " 8   TOPIC: SEQUENCES           215 non-null    object \n",
      " 9   TOPIC: GRAPHING            215 non-null    object \n",
      " 10  TOPIC: MEASURES            215 non-null    object \n",
      " 11  TOPIC: 2D GEOMETRY         215 non-null    object \n",
      " 12  TOPIC: 3D GEOMETRY         215 non-null    object \n",
      " 13  TOPIC: PYTHAG & TRIG       215 non-null    object \n",
      " 14  TOPIC: TRANSFORMATIONS     215 non-null    object \n",
      " 15  TOPIC: ANGLES              215 non-null    object \n",
      " 16  TOPIC: DATA & AVERAGES     215 non-null    object \n",
      " 17  TOPIC: REPRESENTING DATA   215 non-null    object \n",
      " 18  TOPIC: PROBABILITY         215 non-null    object \n",
      " 19  Final grade                211 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(18)\n",
      "memory usage: 33.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_skills = pd.read_csv(\"data/gcse-higher-by-skill.csv\")\n",
    "df_skills.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fdf6180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skills.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04de431b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['94%', '100%', '83%', '89%', '78%', '61%', '72%', '39%', '67%',\n",
       "       '45%', '56%', '0%', '81%', '69%', '88%', '50%', 'N', '31%', '75%',\n",
       "       '63%', '38%', '60%', '80%', '44%'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice above: 'object' not number data types \n",
    "# let's find how values are encoded\n",
    "df_skills['TOPIC: FRACTIONS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13a27578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Final year</th>\n",
       "      <th>Class</th>\n",
       "      <th>TOPIC: NUMBER SKILLS</th>\n",
       "      <th>TOPIC: FRACTIONS</th>\n",
       "      <th>TOPIC: PERCENTAGES</th>\n",
       "      <th>TOPIC: RATIO &amp; PROPORTION</th>\n",
       "      <th>TOPIC: ALGEBRA SKILLS</th>\n",
       "      <th>TOPIC: SEQUENCES</th>\n",
       "      <th>TOPIC: GRAPHING</th>\n",
       "      <th>TOPIC: MEASURES</th>\n",
       "      <th>TOPIC: 2D GEOMETRY</th>\n",
       "      <th>TOPIC: 3D GEOMETRY</th>\n",
       "      <th>TOPIC: PYTHAG &amp; TRIG</th>\n",
       "      <th>TOPIC: TRANSFORMATIONS</th>\n",
       "      <th>TOPIC: ANGLES</th>\n",
       "      <th>TOPIC: DATA &amp; AVERAGES</th>\n",
       "      <th>TOPIC: REPRESENTING DATA</th>\n",
       "      <th>TOPIC: PROBABILITY</th>\n",
       "      <th>Final grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANDERSON Noah</td>\n",
       "      <td>2023</td>\n",
       "      <td>11X1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.57</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AXELSEN Katherine</td>\n",
       "      <td>2023</td>\n",
       "      <td>11X1</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARCLAY Kieran</td>\n",
       "      <td>2023</td>\n",
       "      <td>11X1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BARSTOW Sophia</td>\n",
       "      <td>2023</td>\n",
       "      <td>11X1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.57</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BROWN Freddie</td>\n",
       "      <td>2023</td>\n",
       "      <td>11X1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name  Final year Class  TOPIC: NUMBER SKILLS  \\\n",
       "0      ANDERSON Noah        2023  11X1                  0.67   \n",
       "1  AXELSEN Katherine        2023  11X1                  0.79   \n",
       "2     BARCLAY Kieran        2023  11X1                  0.57   \n",
       "3     BARSTOW Sophia        2023  11X1                  0.74   \n",
       "4      BROWN Freddie        2023  11X1                  0.93   \n",
       "\n",
       "   TOPIC: FRACTIONS  TOPIC: PERCENTAGES  TOPIC: RATIO & PROPORTION  \\\n",
       "0              0.94                0.80                       0.83   \n",
       "1              1.00                0.95                       0.71   \n",
       "2              0.83                0.85                       0.75   \n",
       "3              0.94                0.95                       0.96   \n",
       "4              1.00                1.00                       0.88   \n",
       "\n",
       "   TOPIC: ALGEBRA SKILLS  TOPIC: SEQUENCES  TOPIC: GRAPHING  TOPIC: MEASURES  \\\n",
       "0                   0.52              0.33             0.32             0.67   \n",
       "1                   0.57              0.50             0.73             0.78   \n",
       "2                   0.48              0.33             0.46             0.33   \n",
       "3                   0.63              0.75             0.68             0.44   \n",
       "4                   0.94              1.00             0.92             1.00   \n",
       "\n",
       "   TOPIC: 2D GEOMETRY  TOPIC: 3D GEOMETRY  TOPIC: PYTHAG & TRIG  \\\n",
       "0                0.42                0.43                  0.29   \n",
       "1                0.32                0.43                  0.55   \n",
       "2                0.37                0.33                  0.84   \n",
       "3                0.26                0.62                  0.39   \n",
       "4                0.84                1.00                  1.00   \n",
       "\n",
       "   TOPIC: TRANSFORMATIONS  TOPIC: ANGLES  TOPIC: DATA & AVERAGES  \\\n",
       "0                    0.33           0.25                    1.00   \n",
       "1                    0.67           0.25                    1.00   \n",
       "2                    0.33           0.25                    1.00   \n",
       "3                    0.50           0.00                    0.91   \n",
       "4                    0.50           1.00                    1.00   \n",
       "\n",
       "   TOPIC: REPRESENTING DATA  TOPIC: PROBABILITY  Final grade  \n",
       "0                      0.70                0.57          6.0  \n",
       "1                      0.78                0.86          8.0  \n",
       "2                      0.57                1.00          6.0  \n",
       "3                      0.78                0.57          7.0  \n",
       "4                      0.87                1.00          9.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 'N' rows and null rows\n",
    "# also encode '%' rows (which are actually strings) as float\n",
    "df_skills = df_skills.dropna()\n",
    "for column in df_skills:\n",
    "    if column[0:5]==\"TOPIC\":\n",
    "        # remove all rows with 'N' (df[df[column]=='N'].index returns list of all such rows)\n",
    "        df_skills.drop(df_skills[df_skills[column]=='N'].index,inplace=True)\n",
    "        # remove last character ('%') and encode integer as decimal\n",
    "        df_skills[column] = df_skills[column].str[:-1].astype('float') / 100\n",
    "df_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4598f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skills.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615eebd",
   "metadata": {},
   "source": [
    "We have lost only 6 rows after dropping null values and those encoded as 'N' so this is promising.\n",
    "\n",
    "Let's try getting some results by skill and comparing them to our previous results.\n",
    "\n",
    "First, remove unnecessary rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc3563ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPIC: NUMBER SKILLS</th>\n",
       "      <th>TOPIC: FRACTIONS</th>\n",
       "      <th>TOPIC: PERCENTAGES</th>\n",
       "      <th>TOPIC: RATIO &amp; PROPORTION</th>\n",
       "      <th>TOPIC: ALGEBRA SKILLS</th>\n",
       "      <th>TOPIC: SEQUENCES</th>\n",
       "      <th>TOPIC: GRAPHING</th>\n",
       "      <th>TOPIC: MEASURES</th>\n",
       "      <th>TOPIC: 2D GEOMETRY</th>\n",
       "      <th>TOPIC: 3D GEOMETRY</th>\n",
       "      <th>TOPIC: PYTHAG &amp; TRIG</th>\n",
       "      <th>TOPIC: TRANSFORMATIONS</th>\n",
       "      <th>TOPIC: ANGLES</th>\n",
       "      <th>TOPIC: DATA &amp; AVERAGES</th>\n",
       "      <th>TOPIC: REPRESENTING DATA</th>\n",
       "      <th>TOPIC: PROBABILITY</th>\n",
       "      <th>Final grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.57</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.57</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOPIC: NUMBER SKILLS  TOPIC: FRACTIONS  TOPIC: PERCENTAGES  \\\n",
       "0                  0.67              0.94                0.80   \n",
       "1                  0.79              1.00                0.95   \n",
       "2                  0.57              0.83                0.85   \n",
       "3                  0.74              0.94                0.95   \n",
       "4                  0.93              1.00                1.00   \n",
       "\n",
       "   TOPIC: RATIO & PROPORTION  TOPIC: ALGEBRA SKILLS  TOPIC: SEQUENCES  \\\n",
       "0                       0.83                   0.52              0.33   \n",
       "1                       0.71                   0.57              0.50   \n",
       "2                       0.75                   0.48              0.33   \n",
       "3                       0.96                   0.63              0.75   \n",
       "4                       0.88                   0.94              1.00   \n",
       "\n",
       "   TOPIC: GRAPHING  TOPIC: MEASURES  TOPIC: 2D GEOMETRY  TOPIC: 3D GEOMETRY  \\\n",
       "0             0.32             0.67                0.42                0.43   \n",
       "1             0.73             0.78                0.32                0.43   \n",
       "2             0.46             0.33                0.37                0.33   \n",
       "3             0.68             0.44                0.26                0.62   \n",
       "4             0.92             1.00                0.84                1.00   \n",
       "\n",
       "   TOPIC: PYTHAG & TRIG  TOPIC: TRANSFORMATIONS  TOPIC: ANGLES  \\\n",
       "0                  0.29                    0.33           0.25   \n",
       "1                  0.55                    0.67           0.25   \n",
       "2                  0.84                    0.33           0.25   \n",
       "3                  0.39                    0.50           0.00   \n",
       "4                  1.00                    0.50           1.00   \n",
       "\n",
       "   TOPIC: DATA & AVERAGES  TOPIC: REPRESENTING DATA  TOPIC: PROBABILITY  \\\n",
       "0                    1.00                      0.70                0.57   \n",
       "1                    1.00                      0.78                0.86   \n",
       "2                    1.00                      0.57                1.00   \n",
       "3                    0.91                      0.78                0.57   \n",
       "4                    1.00                      0.87                1.00   \n",
       "\n",
       "   Final grade  \n",
       "0          6.0  \n",
       "1          8.0  \n",
       "2          6.0  \n",
       "3          7.0  \n",
       "4          9.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skills = df_skills.drop(columns=['Name','Final year','Class'])\n",
    "df_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7170acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 22 models\n",
      "\n",
      "logistic = 0.4788\n",
      "ridge-0.3 = 0.4061\n",
      "ridge-0.7 = 0.4\n",
      "ridge-1.0 = 0.3515\n",
      "sgd = 0.3394\n",
      "pa = 0.2909\n",
      "knn-3 = 0.4424\n",
      "knn-7 = 0.5091\n",
      "knn-15 = 0.5273\n",
      "cart = 0.5091\n",
      "extra = 0.4667\n",
      "svml = 0.5333\n",
      "svmp = 0.5394\n",
      "svmr0.3 = 0.4606\n",
      "svmr0.7 = 0.4727\n",
      "svmr1.0 = 0.5333\n",
      "bayes = 0.5879\n",
      "ada = 0.4\n",
      "bag = 0.5939\n",
      "rf = 0.5636\n",
      "et = 0.5455\n",
      "gbm = 0.4606\n",
      "\n",
      "Best 10\n",
      "=======\n",
      "[('bag', 0.5939),\n",
      " ('bayes', 0.5879),\n",
      " ('rf', 0.5636),\n",
      " ('et', 0.5455),\n",
      " ('svmp', 0.5394),\n",
      " ('svml', 0.5333),\n",
      " ('svmr1.0', 0.5333),\n",
      " ('knn-15', 0.5273),\n",
      " ('knn-7', 0.5091),\n",
      " ('cart', 0.5091)]\n"
     ]
    }
   ],
   "source": [
    "models_by_skill = define_models()\n",
    "X = df_skills.drop([\"Final grade\"], axis=1)\n",
    "y = df_skills[\"Final grade\"]\n",
    "\n",
    "results_by_skill = {}\n",
    "        \n",
    "for key,model in models.items(): \n",
    "\n",
    "    # Get results\n",
    "    model_result = np.mean(predict_and_calc_accuracy(model, X, y))#np.mean([predict_and_calc_accuracy(X.tail(-1),y.tail(-1),model).mean() for _ in range(1,3+1)])\n",
    "    model_result = round(model_result, 4)\n",
    "    results_by_skill[key] = model_result\n",
    "    print(f'{key} = {model_result}')\n",
    "        \n",
    "results_by_skill = sorted(results_by_skill.items(),reverse=True,key=lambda item: item[1])[:10]\n",
    "\n",
    "print()\n",
    "print(\"Best 10\")\n",
    "print(\"=======\")\n",
    "pp.pprint(results_by_skill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c4f09d",
   "metadata": {},
   "source": [
    "It would appear that the results are less accurate when data is grouped by skill compared to grouped by test score.\n",
    "\n",
    "Therefore we will return to our initial approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17c694",
   "metadata": {},
   "source": [
    "### Look at best model using a confusion matrix and confusion report\n",
    "\n",
    "The joint best model is a __[Gradient Boosting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)__ with 100 estimators, with the data being in df1 (where missing values were replaced by median values).\n",
    "\n",
    "Let's explore its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fed33879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, '9'),\n",
       " Text(0, 1.5, '8'),\n",
       " Text(0, 2.5, '7'),\n",
       " Text(0, 3.5, '6'),\n",
       " Text(0, 4.5, '5'),\n",
       " Text(0, 5.5, '4')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = [9,8,7,6,5,4]\n",
    "fx=sns.heatmap(confusion_matrix(y_test,y_preds), annot=True, fmt=\".2f\",cmap=\"GnBu\")\n",
    "fx.set_title('Confusion Matrix \\n');\n",
    "fx.set_xlabel('\\n Predicted Values\\n')\n",
    "fx.set_ylabel('Actual Values\\n');\n",
    "fx.xaxis.set_ticklabels(labels)\n",
    "fx.yaxis.set_ticklabels(labels)\n",
    "#fx.figure(figsize=(10,6))\n",
    "#fx.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8668da",
   "metadata": {},
   "source": [
    "Although the central spine (top-left to bottom-right) of correct predictions is solid, there are still a number of predictions that are either side of the line and therefore incorrect.\n",
    "\n",
    "### Out of interest: Which features carried the greatest weight?\n",
    "\n",
    "Let's check the relative weight of each feature in making the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69ef1e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Y7 AVG': 0.02468719804780326, 'Y8 AVG': 0.05501068805322771, 'Y9 AVG': 0.059231025030798364, 'Y10 AVG': 0.055688570149461845, 'Y10 MOCK AVG': 0.03650168882550926, 'Y11 NOV MOCK AVG': 0.050218398182883726, 'Y11 MAR MOCK AVG': 0.7186624317103159}\n"
     ]
    }
   ],
   "source": [
    "feature_importances_dict = dict(zip(X.columns,model.feature_importances_))\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6ce80",
   "metadata": {},
   "source": [
    "By far the highest weight goes to the final mock grade a few months before the exam: 71%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eec88f",
   "metadata": {},
   "source": [
    "### Summary\n",
    "<a name=\"conclusion\"></a>\n",
    "\n",
    "At 65%, the Gradient Boosting Classifier model is showing a promising degree of accuracy compared to our minimum requirement of 60%. However this result is not high enough above the success threshold yet to feel confident about the model's universal validity going forward.\n",
    "\n",
    "On the plus side, in addition to the accuracy, errors seem to be evenly distributed either side of being correct (some predictions above, some below), with only one result more than one grade away from the correct prediction.\n",
    "\n",
    "The most important potential negative is that we don't know about overfitting yet.\n",
    "\n",
    "We now need to see if hyperparameter tuning can improve the accuracy of the model sufficiently above 60% to make it a viable alternative to teacher predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f2907",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning spot-check: can the basic model be improved?\n",
    "\n",
    "[Mohtadi Ben Fraj](https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae) provides a deep overview of the steps for a Gradient Boosting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e1d47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_grid = {\n",
    "    'learning_rate' : [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "    'n_estimators' : [1, 2, 4, 8, 16, 32, 64, 100, 200],\n",
    "    'max_depth' : np.linspace(1, 32, 32, endpoint=True, dtype=int),\n",
    "    'min_samples_split' : np.linspace(0.1, 1.0, 5, endpoint=True),\n",
    "    'min_samples_leaf' : np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "    'max_features' : list(range(1,df1.shape[1])),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9396ec0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "{'n_estimators': 100, 'min_samples_split': 0.775, 'min_samples_leaf': 0.1, 'max_features': 4, 'max_depth': 1, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "gbm_random_search = RandomizedSearchCV(\n",
    "    estimator = models['gbm'], \n",
    "    param_distributions = gbm_grid, \n",
    "    n_iter = 40, \n",
    "    cv = 5, \n",
    "    verbose = 3, \n",
    "    random_state=42, \n",
    "    n_jobs = -1,\n",
    ")\n",
    "\n",
    "gbm_random_search.fit(X_train, y_train)\n",
    "\n",
    "print(gbm_random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "734c651f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6096256684491979"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_random_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7f25bf",
   "metadata": {},
   "source": [
    "## Evaluation and future experimentation\n",
    "<a name=\"experiment\"></a>\n",
    "\n",
    "This result suggests we have reached the end of the road (for now).\n",
    "\n",
    "We discovered that we could achieve 65% accuracy with a vanilla Gradient Boosting Classifier, which was 5% higher than our success criteria.\n",
    "\n",
    "However hyperparameter tuning has created a best score of only 61%, when we are expecting a score increase!\n",
    "\n",
    "The issue here is almost certainly not enough data to use for training the model.\n",
    "\n",
    "I will return to the model when I have more data to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734f265",
   "metadata": {},
   "source": [
    "## Appendix 1: Halving Grid Search as alternative hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ddbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "gbm_halving_grid = {\n",
    "    'model__learning_rate' : [1, 0.667, 0.444, 0.296, 0.198, 0.132, 0.088, 0.058, 0.02, 0.01],\n",
    "    'model__n_estimators' : [1, 2, 4, 8, 16, 32, 64, 100, 200],\n",
    "    'model__max_depth' : [1, 4, 8, 12, 16, 20, 24, 28, 32],#np.linspace(1, 32, 32, endpoint=True),\n",
    "    'model__min_samples_split' : np.linspace(0.1, 1.0, 5, endpoint=True),\n",
    "    'model__min_samples_leaf' : np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "    'model__max_features' : list(range(1,df1.shape[1])),\n",
    "}\n",
    "\n",
    "gbm_halving = HalvingGridSearchCV(\n",
    "    estimator = models['gbm'], \n",
    "    resource='n_samples',\n",
    "    #min_resources=len(X_train) // 4,\n",
    "    factor=2, \n",
    "    param_grid=gbm_grid, \n",
    ")\n",
    "\n",
    "gbm_halving.fit(X_train, y_train)\n",
    "\n",
    "print(gbm_halving.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a475354",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_best = GradientBoostingClassifier(**gbm_random.best_params_)\n",
    "\n",
    "gbm_best.fit(X_train, y_train)\n",
    "\n",
    "y_preds = gbm_best.predict(X_test)\n",
    "\n",
    "print(f'Confusion Matrix')\n",
    "print(f'================')\n",
    "print(confusion_matrix(y_test,y_preds))\n",
    "print()\n",
    "print(f'Confusion Report')\n",
    "print(f'================')\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d939bc3",
   "metadata": {},
   "source": [
    "## Appendix 2: Alternative tuning methodology - for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#gbm_random = RandomizedSearchCV(\n",
    "#    estimator = models['gbm'], \n",
    "#    param_distributions = gbm_grid, \n",
    "#    n_iter = 20, \n",
    "#    cv = 5, \n",
    "#    verbose = 2, \n",
    "#    random_state=42, \n",
    "#    n_jobs = -1,\n",
    "#)\n",
    "\n",
    "#bag_random = RandomizedSearchCV(\n",
    "#    estimator = models['bag'], \n",
    "#    param_distributions = bag_grid, \n",
    "#    n_iter = 10, \n",
    "#    cv = 5, \n",
    "#    verbose = 2, \n",
    "#    random_state=42, \n",
    "#    n_jobs = -1,\n",
    "#)\n",
    "\n",
    "gbm_models = []\n",
    "for learning_rate in gbm_grid['learning_rate']:\n",
    "    this_model = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state = 42,\n",
    "        )\n",
    "    this_result = np.mean(predict_and_calc_accuracy(this_model,X,y))\n",
    "    gbm_models.append({\n",
    "        'model' : this_model,\n",
    "        'learning_rate' : learning_rate,\n",
    "        'result' : this_result,\n",
    "    })\n",
    "    print(f'learning_rate={learning_rate}, accuracy={this_result}')\n",
    "    \n",
    "#gbm_random.fit(X_train, y_train)\n",
    "\n",
    "#gbm_random.best_params_\n",
    "\n",
    "\n",
    "#bag_random.fit(X_train, y_train)\n",
    "#\n",
    "#bag_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_learning_rate = 0.444\n",
    "\n",
    "for n_estimators in gbm_grid['n_estimators']:\n",
    "    this_model = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=best_learning_rate,\n",
    "        random_state = 42,\n",
    "        )\n",
    "    this_result = np.mean(predict_and_calc_accuracy(this_model,X,y))\n",
    "    gbm_models.append({\n",
    "        'model' : this_model,\n",
    "        'learning_rate' : learning_rate,\n",
    "        'n_estimators' : n_estimators,\n",
    "        'result' : this_result,\n",
    "    })\n",
    "    print(f'n_estimators={n_estimators}, accuracy={this_result}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd68c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_estimators = 32\n",
    "\n",
    "for max_depth in gbm_grid['max_depth']:\n",
    "    this_model = GradientBoostingClassifier(\n",
    "        n_estimators=best_n_estimators,\n",
    "        learning_rate=best_learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        random_state = 42,\n",
    "        )\n",
    "    this_result = np.mean(predict_and_calc_accuracy(this_model,X,y))\n",
    "    gbm_models.append({\n",
    "        'model' : this_model,\n",
    "        'learning_rate' : learning_rate,\n",
    "        'n_estimators' : n_estimators,\n",
    "        'max_depth' : max_depth,\n",
    "        'result' : this_result,\n",
    "    })\n",
    "    print(f'max_depth={max_depth}, accuracy={this_result}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78453d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_depth = 20\n",
    "\n",
    "for min_samples_split in gbm_grid['min_samples_split']:\n",
    "    this_model = GradientBoostingClassifier(\n",
    "        n_estimators=best_n_estimators,\n",
    "        learning_rate=best_learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state = 42,\n",
    "        )\n",
    "    this_result = np.mean(predict_and_calc_accuracy(this_model,X,y))\n",
    "    gbm_models.append({\n",
    "        'model' : this_model,\n",
    "        'learning_rate' : learning_rate,\n",
    "        'n_estimators' : n_estimators,\n",
    "        'max_depth' : max_depth,\n",
    "        'min_samples_split' : min_samples_split,\n",
    "        'result' : this_result,\n",
    "    })\n",
    "    print(f'min_samples_split={min_samples_split}, accuracy={this_result}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf55ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_min_samples_split = 0.55\n",
    "\n",
    "for min_samples_leaf in gbm_grid['min_samples_leaf']:\n",
    "    this_model = GradientBoostingClassifier(\n",
    "        n_estimators=best_n_estimators,\n",
    "        learning_rate=best_learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state = 42,\n",
    "        )\n",
    "    this_result = np.mean(predict_and_calc_accuracy(this_model,X,y))\n",
    "    gbm_models.append({\n",
    "        'model' : this_model,\n",
    "        'learning_rate' : learning_rate,\n",
    "        'n_estimators' : n_estimators,\n",
    "        'max_depth' : max_depth,\n",
    "        'min_samples_split' : min_samples_split,\n",
    "        'min_samples_leaf' : min_samples_leaf,\n",
    "        'result' : this_result,\n",
    "    })\n",
    "    print(f'min_samples_leaf={min_samples_leaf}, accuracy={this_result}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e9ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
